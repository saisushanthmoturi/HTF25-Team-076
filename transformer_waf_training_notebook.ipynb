{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fab87551",
   "metadata": {},
   "source": [
    "# Transformer WAF - LogBERT Training & Preprocessing Notebook\n",
    "\n",
    "This notebook demonstrates the preprocessing and training pipeline for the LogBERT-based Web Application Firewall.\n",
    "\n",
    "## Overview\n",
    "- **Data Source**: Live Tomcat access logs\n",
    "- **Model**: LogBERT Transformer for anomaly detection\n",
    "- **Training**: Unsupervised learning on benign traffic patterns\n",
    "- **Output**: Trained model for real-time anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d5cd25",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528b01bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üìö Libraries imported successfully!\")\n",
    "print(f\"üêç Python version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39adbbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import WAF components\n",
    "try:\n",
    "    from log_parser_normalizer import LogParserNormalizer\n",
    "    from logbert_transformer_model import LogBERTModel, LogBERTConfig\n",
    "    from waf_training_pipeline import WAFTrainingPipeline\n",
    "    from incremental_lora_learning import LoRAIncrementalLearner\n",
    "    print(\"‚úÖ WAF components imported successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Error importing WAF components: {e}\")\n",
    "    print(\"Make sure all WAF Python files are in the same directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5044ca41",
   "metadata": {},
   "source": [
    "## 2. Configuration and Data Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087b54ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    'data_paths': {\n",
    "        'tomcat_logs': '/opt/tomcat/logs',\n",
    "        'local_logs': 'logs',\n",
    "        'sample_logs': 'sample_data/access_logs.txt'\n",
    "    },\n",
    "    'model_config': {\n",
    "        'vocab_size': 10000,\n",
    "        'hidden_size': 256,\n",
    "        'num_layers': 6,\n",
    "        'num_heads': 8,\n",
    "        'max_sequence_length': 512\n",
    "    },\n",
    "    'training': {\n",
    "        'batch_size': 32,\n",
    "        'learning_rate': 2e-5,\n",
    "        'num_epochs': 3,\n",
    "        'warmup_steps': 100\n",
    "    },\n",
    "    'output_paths': {\n",
    "        'models': 'models',\n",
    "        'plots': 'plots',\n",
    "        'reports': 'reports'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create directories\n",
    "for path in CONFIG['output_paths'].values():\n",
    "    Path(path).mkdir(exist_ok=True)\n",
    "    \n",
    "print(\"üìÅ Directories created successfully!\")\n",
    "print(json.dumps(CONFIG, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85ad7bd",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0855d5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_log_files(log_directories):\n",
    "    \"\"\"Load log files from multiple directories\"\"\"\n",
    "    log_entries = []\n",
    "    \n",
    "    for log_dir in log_directories:\n",
    "        log_path = Path(log_dir)\n",
    "        if not log_path.exists():\n",
    "            print(f\"‚ö†Ô∏è Directory not found: {log_path}\")\n",
    "            continue\n",
    "            \n",
    "        # Find log files\n",
    "        log_files = list(log_path.glob(\"*.log\"))\n",
    "        print(f\"üìÅ Found {len(log_files)} log files in {log_path}\")\n",
    "        \n",
    "        for log_file in log_files:\n",
    "            try:\n",
    "                with open(log_file, 'r', encoding='utf-8') as f:\n",
    "                    lines = f.readlines()\n",
    "                    for line in lines:\n",
    "                        line = line.strip()\n",
    "                        if line:\n",
    "                            log_entries.append({\n",
    "                                'raw_log': line,\n",
    "                                'file': str(log_file),\n",
    "                                'timestamp': datetime.now()\n",
    "                            })\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error reading {log_file}: {e}\")\n",
    "                \n",
    "    return log_entries\n",
    "\n",
    "# Load logs\n",
    "log_directories = [\n",
    "    CONFIG['data_paths']['local_logs'],\n",
    "    # Add other directories as they become available\n",
    "]\n",
    "\n",
    "raw_logs = load_log_files(log_directories)\n",
    "print(f\"üìä Loaded {len(raw_logs)} log entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28054b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data if no logs are found\n",
    "if len(raw_logs) == 0:\n",
    "    print(\"üîß Generating sample log data for demonstration...\")\n",
    "    \n",
    "    sample_logs = [\n",
    "        '192.168.1.100 - - [01/Dec/2023:10:00:00 +0000] \"GET /index.html HTTP/1.1\" 200 2345 \"-\" \"Mozilla/5.0\"',\n",
    "        '192.168.1.101 - - [01/Dec/2023:10:00:01 +0000] \"POST /api/login HTTP/1.1\" 200 567 \"http://example.com/login\" \"Mozilla/5.0\"',\n",
    "        '192.168.1.102 - - [01/Dec/2023:10:00:02 +0000] \"GET /products?id=123 HTTP/1.1\" 200 1234 \"-\" \"Mozilla/5.0\"',\n",
    "        '192.168.1.103 - - [01/Dec/2023:10:00:03 +0000] \"GET /api/users HTTP/1.1\" 200 890 \"-\" \"curl/7.68.0\"',\n",
    "        '192.168.1.104 - - [01/Dec/2023:10:00:04 +0000] \"POST /checkout HTTP/1.1\" 200 456 \"http://example.com/cart\" \"Mozilla/5.0\"',\n",
    "        # Potentially anomalous entries\n",
    "        '192.168.1.105 - - [01/Dec/2023:10:00:05 +0000] \"GET /admin/../../etc/passwd HTTP/1.1\" 404 123 \"-\" \"curl/7.68.0\"',\n",
    "        '192.168.1.106 - - [01/Dec/2023:10:00:06 +0000] \"POST /search?q=<script>alert(1)</script> HTTP/1.1\" 200 789 \"-\" \"Mozilla/5.0\"',\n",
    "    ]\n",
    "    \n",
    "    raw_logs = []\n",
    "    for i, log in enumerate(sample_logs * 50):  # Multiply for more data\n",
    "        raw_logs.append({\n",
    "            'raw_log': log,\n",
    "            'file': 'sample_data',\n",
    "            'timestamp': datetime.now() + timedelta(seconds=i)\n",
    "        })\n",
    "        \n",
    "    print(f\"‚úÖ Generated {len(raw_logs)} sample log entries\")\n",
    "\n",
    "# Show first few logs\n",
    "print(\"\\nüìã Sample log entries:\")\n",
    "for i, log in enumerate(raw_logs[:5]):\n",
    "    print(f\"{i+1}. {log['raw_log'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc95ead",
   "metadata": {},
   "source": [
    "## 4. Log Parsing and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef223fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize log parser\n",
    "log_parser = LogParserNormalizer()\n",
    "await log_parser.initialize()\n",
    "\n",
    "print(\"üîß Log parser initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd3f9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_clf_log(log_line):\n",
    "    \"\"\"Parse Common Log Format log entry\"\"\"\n",
    "    # CLF regex pattern\n",
    "    clf_pattern = re.compile(\n",
    "        r'(?P<remote_addr>\\S+) \\S+ \\S+ \\[(?P<timestamp>[^\\]]+)\\] '\n",
    "        r'\"(?P<method>\\S+) (?P<uri>\\S+) (?P<protocol>[^\"]+)\" '\n",
    "        r'(?P<status>\\d+) (?P<bytes_sent>\\S+)'\n",
    "        r'(?: \"(?P<referer>[^\"]*)\" \"(?P<user_agent>[^\"]*)\")?'\n",
    "    )\n",
    "    \n",
    "    match = clf_pattern.match(log_line)\n",
    "    if not match:\n",
    "        return None\n",
    "        \n",
    "    groups = match.groupdict()\n",
    "    \n",
    "    # Parse URI and query string\n",
    "    uri = groups.get('uri', '')\n",
    "    query_string = ''\n",
    "    if '?' in uri:\n",
    "        uri, query_string = uri.split('?', 1)\n",
    "        \n",
    "    return {\n",
    "        'timestamp': groups.get('timestamp', ''),\n",
    "        'remote_addr': groups.get('remote_addr', ''),\n",
    "        'method': groups.get('method', ''),\n",
    "        'uri': uri,\n",
    "        'query_string': query_string,\n",
    "        'protocol': groups.get('protocol', ''),\n",
    "        'status': int(groups.get('status', 0)),\n",
    "        'bytes_sent': int(groups.get('bytes_sent', 0)) if groups.get('bytes_sent', '-') != '-' else 0,\n",
    "        'referer': groups.get('referer', ''),\n",
    "        'user_agent': groups.get('user_agent', '')\n",
    "    }\n",
    "\n",
    "# Parse all logs\n",
    "parsed_logs = []\n",
    "parsing_errors = 0\n",
    "\n",
    "print(\"üîç Parsing log entries...\")\n",
    "for log_entry in raw_logs:\n",
    "    try:\n",
    "        parsed = parse_clf_log(log_entry['raw_log'])\n",
    "        if parsed:\n",
    "            # Add template using Drain algorithm\n",
    "            template = log_parser.parse_log(parsed['uri'])\n",
    "            parsed['template'] = template\n",
    "            parsed['file'] = log_entry['file']\n",
    "            parsed_logs.append(parsed)\n",
    "        else:\n",
    "            parsing_errors += 1\n",
    "    except Exception as e:\n",
    "        parsing_errors += 1\n",
    "        \n",
    "print(f\"‚úÖ Successfully parsed {len(parsed_logs)} log entries\")\n",
    "print(f\"‚ö†Ô∏è Parsing errors: {parsing_errors}\")\n",
    "\n",
    "# Convert to DataFrame for easier analysis\n",
    "df_logs = pd.DataFrame(parsed_logs)\n",
    "print(f\"üìä Created DataFrame with shape: {df_logs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4073c0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic statistics\n",
    "print(\"üìà Log Data Overview:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total log entries: {len(df_logs)}\")\n",
    "print(f\"Unique IP addresses: {df_logs['remote_addr'].nunique()}\")\n",
    "print(f\"Unique URIs: {df_logs['uri'].nunique()}\")\n",
    "print(f\"Unique templates: {df_logs['template'].nunique()}\")\n",
    "print(f\"Date range: {df_logs['timestamp'].min()} to {df_logs['timestamp'].max()}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nüìã Sample parsed logs:\")\n",
    "display(df_logs.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d250972c",
   "metadata": {},
   "source": [
    "## 5. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f67405c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTTP methods distribution\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "method_counts = df_logs['method'].value_counts()\n",
    "plt.pie(method_counts.values, labels=method_counts.index, autopct='%1.1f%%')\n",
    "plt.title('HTTP Methods Distribution')\n",
    "\n",
    "# Status codes distribution\n",
    "plt.subplot(1, 3, 2)\n",
    "status_counts = df_logs['status'].value_counts().head(10)\n",
    "plt.bar(range(len(status_counts)), status_counts.values)\n",
    "plt.xticks(range(len(status_counts)), status_counts.index, rotation=45)\n",
    "plt.title('Top 10 Status Codes')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# URI templates distribution\n",
    "plt.subplot(1, 3, 3)\n",
    "template_counts = df_logs['template'].value_counts().head(10)\n",
    "plt.barh(range(len(template_counts)), template_counts.values)\n",
    "plt.yticks(range(len(template_counts)), [t[:30] + '...' if len(t) > 30 else t for t in template_counts.index])\n",
    "plt.title('Top 10 URI Templates')\n",
    "plt.xlabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{CONFIG['output_paths']['plots']}/log_analysis.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Exploratory data analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8d74fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze request patterns\n",
    "print(\"üîç Request Pattern Analysis:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Most common user agents\n",
    "print(\"\\nüï∑Ô∏è Top User Agents:\")\n",
    "ua_counts = df_logs['user_agent'].value_counts().head(5)\n",
    "for ua, count in ua_counts.items():\n",
    "    print(f\"  {count:3d}: {ua[:60]}...\")\n",
    "\n",
    "# Most active IPs\n",
    "print(\"\\nüåê Most Active IP Addresses:\")\n",
    "ip_counts = df_logs['remote_addr'].value_counts().head(5)\n",
    "for ip, count in ip_counts.items():\n",
    "    print(f\"  {count:3d}: {ip}\")\n",
    "\n",
    "# Suspicious patterns\n",
    "print(\"\\nüö® Potential Security Issues:\")\n",
    "suspicious_patterns = [\n",
    "    ('../', 'Directory Traversal'),\n",
    "    ('script>', 'XSS Attempt'),\n",
    "    ('union', 'SQL Injection'),\n",
    "    ('alert(', 'XSS Attempt'),\n",
    "    ('etc/passwd', 'File Access Attempt')\n",
    "]\n",
    "\n",
    "for pattern, attack_type in suspicious_patterns:\n",
    "    suspicious_logs = df_logs[df_logs['uri'].str.contains(pattern, case=False, na=False)]\n",
    "    if len(suspicious_logs) > 0:\n",
    "        print(f\"  {attack_type}: {len(suspicious_logs)} instances\")\n",
    "        for _, log in suspicious_logs.head(2).iterrows():\n",
    "            print(f\"    Example: {log['method']} {log['uri'][:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bcc610",
   "metadata": {},
   "source": [
    "## 6. Feature Engineering and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a0b86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(df):\n",
    "    \"\"\"Extract features from log data for training\"\"\"\n",
    "    features = df.copy()\n",
    "    \n",
    "    # Basic features\n",
    "    features['uri_length'] = features['uri'].str.len()\n",
    "    features['query_length'] = features['query_string'].str.len()\n",
    "    features['has_query'] = (features['query_length'] > 0).astype(int)\n",
    "    \n",
    "    # URI characteristics\n",
    "    features['uri_depth'] = features['uri'].str.count('/')\n",
    "    features['has_params'] = features['uri'].str.contains('\\?').astype(int)\n",
    "    features['has_extension'] = features['uri'].str.contains('\\\\.[a-zA-Z0-9]+$').astype(int)\n",
    "    \n",
    "    # Suspicious pattern indicators\n",
    "    suspicious_patterns = {\n",
    "        'has_traversal': r'\\.\\.[\\\\/]',\n",
    "        'has_script': r'<script',\n",
    "        'has_sql': r'(union|select|insert|update|delete|drop)\\s',\n",
    "        'has_exec': r'(exec|eval|cmd)',\n",
    "        'has_special_chars': r'[<>\"\\';()]'\n",
    "    }\n",
    "    \n",
    "    for feature_name, pattern in suspicious_patterns.items():\n",
    "        features[feature_name] = features['uri'].str.contains(pattern, case=False, regex=True).astype(int)\n",
    "    \n",
    "    # Categorical encoding\n",
    "    features['method_encoded'] = pd.Categorical(features['method']).codes\n",
    "    features['status_class'] = (features['status'] // 100).astype(int)\n",
    "    \n",
    "    # Numerical features\n",
    "    features['bytes_sent_log'] = np.log1p(features['bytes_sent'])\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Extract features\n",
    "print(\"üîß Extracting features...\")\n",
    "df_features = extract_features(df_logs)\n",
    "\n",
    "# Select feature columns for training\n",
    "feature_columns = [\n",
    "    'template', 'method', 'uri', 'status', 'user_agent',\n",
    "    'uri_length', 'query_length', 'has_query', 'uri_depth',\n",
    "    'has_params', 'has_extension', 'has_traversal', 'has_script',\n",
    "    'has_sql', 'has_exec', 'has_special_chars', 'bytes_sent_log'\n",
    "]\n",
    "\n",
    "print(f\"‚úÖ Feature extraction complete! Features: {len(feature_columns)}\")\n",
    "print(f\"Features: {feature_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15e9861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences for LogBERT training\n",
    "def create_training_sequences(df, max_length=512):\n",
    "    \"\"\"Create training sequences from log data\"\"\"\n",
    "    sequences = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        # Create sequence from log components\n",
    "        parts = [\n",
    "            str(row.get('method', '')),\n",
    "            str(row.get('uri', '')),\n",
    "            str(row.get('template', '')),\n",
    "            str(row.get('status', '')),\n",
    "            str(row.get('user_agent', ''))[:100]  # Truncate user agent\n",
    "        ]\n",
    "        \n",
    "        # Join parts and clean\n",
    "        sequence = ' '.join(part for part in parts if part and part != 'nan')\n",
    "        sequence = re.sub(r'\\s+', ' ', sequence).strip()\n",
    "        \n",
    "        if len(sequence) > 0:\n",
    "            sequences.append({\n",
    "                'sequence': sequence[:max_length],\n",
    "                'length': min(len(sequence), max_length),\n",
    "                'original_log': row.to_dict()\n",
    "            })\n",
    "    \n",
    "    return sequences\n",
    "\n",
    "# Create training sequences\n",
    "print(\"üìù Creating training sequences...\")\n",
    "training_sequences = create_training_sequences(df_features)\n",
    "print(f\"‚úÖ Created {len(training_sequences)} training sequences\")\n",
    "\n",
    "# Show sequence statistics\n",
    "sequence_lengths = [seq['length'] for seq in training_sequences]\n",
    "print(f\"\\nüìè Sequence Length Statistics:\")\n",
    "print(f\"  Mean: {np.mean(sequence_lengths):.1f}\")\n",
    "print(f\"  Median: {np.median(sequence_lengths):.1f}\")\n",
    "print(f\"  Max: {max(sequence_lengths)}\")\n",
    "print(f\"  Min: {min(sequence_lengths)}\")\n",
    "\n",
    "# Show sample sequences\n",
    "print(\"\\nüìã Sample Training Sequences:\")\n",
    "for i, seq in enumerate(training_sequences[:3]):\n",
    "    print(f\"{i+1}. {seq['sequence'][:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31c2ce1",
   "metadata": {},
   "source": [
    "## 7. Model Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a156ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LogBERT model\n",
    "print(\"ü§ñ Initializing LogBERT model...\")\n",
    "\n",
    "# Create model configuration\n",
    "model_config = LogBERTConfig(\n",
    "    vocab_size=CONFIG['model_config']['vocab_size'],\n",
    "    hidden_size=CONFIG['model_config']['hidden_size'],\n",
    "    num_hidden_layers=CONFIG['model_config']['num_layers'],\n",
    "    num_attention_heads=CONFIG['model_config']['num_heads'],\n",
    "    max_position_embeddings=CONFIG['model_config']['max_sequence_length'],\n",
    "    intermediate_size=CONFIG['model_config']['hidden_size'] * 4\n",
    ")\n",
    "\n",
    "# Initialize model\n",
    "model = LogBERTModel(model_config)\n",
    "print(f\"‚úÖ LogBERT model initialized with {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
    "\n",
    "# Print model architecture\n",
    "print(f\"\\nüèóÔ∏è Model Architecture:\")\n",
    "print(f\"  Vocab Size: {model_config.vocab_size:,}\")\n",
    "print(f\"  Hidden Size: {model_config.hidden_size}\")\n",
    "print(f\"  Layers: {model_config.num_hidden_layers}\")\n",
    "print(f\"  Attention Heads: {model_config.num_attention_heads}\")\n",
    "print(f\"  Max Sequence Length: {model_config.max_position_embeddings}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c585489b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize training pipeline\n",
    "print(\"üöÄ Initializing training pipeline...\")\n",
    "\n",
    "# Create training pipeline\n",
    "training_pipeline = WAFTrainingPipeline(\n",
    "    model_config=model_config,\n",
    "    batch_size=CONFIG['training']['batch_size'],\n",
    "    learning_rate=CONFIG['training']['learning_rate'],\n",
    "    num_epochs=CONFIG['training']['num_epochs']\n",
    ")\n",
    "\n",
    "# Prepare training data\n",
    "benign_sequences = []\n",
    "for seq in training_sequences:\n",
    "    # Simple benign filtering (in practice, this would be more sophisticated)\n",
    "    log_data = seq['original_log']\n",
    "    if (log_data.get('status', 0) in [200, 201, 301, 302, 304, 404] and\n",
    "        not any(log_data.get(f'has_{pattern}', False) for pattern in ['traversal', 'script', 'sql', 'exec'])):\n",
    "        benign_sequences.append(seq['sequence'])\n",
    "\n",
    "print(f\"‚úÖ Prepared {len(benign_sequences)} benign training sequences\")\n",
    "print(f\"üìä Training data split: {len(benign_sequences)} benign sequences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fc0e6c",
   "metadata": {},
   "source": [
    "## 8. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3077a31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"üèãÔ∏è Starting model training...\")\n",
    "print(\"This may take several minutes depending on the data size and hardware.\")\n",
    "\n",
    "try:\n",
    "    # Train the model\n",
    "    training_results = await training_pipeline.train(\n",
    "        train_sequences=benign_sequences,\n",
    "        save_path=CONFIG['output_paths']['models']\n",
    "    )\n",
    "    \n",
    "    print(\"\\nüéâ Training completed successfully!\")\n",
    "    print(f\"üìà Training Results:\")\n",
    "    for key, value in training_results.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Training failed: {e}\")\n",
    "    print(\"üí° This is expected if running in demo mode without GPU support.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3013f3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training metrics (if training was successful)\n",
    "if 'training_results' in locals() and training_results:\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # Training loss\n",
    "    if 'train_losses' in training_results:\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(training_results['train_losses'])\n",
    "        plt.title('Training Loss')\n",
    "        plt.xlabel('Step')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.grid(True)\n",
    "    \n",
    "    # Learning rate schedule\n",
    "    if 'learning_rates' in training_results:\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(training_results['learning_rates'])\n",
    "        plt.title('Learning Rate Schedule')\n",
    "        plt.xlabel('Step')\n",
    "        plt.ylabel('Learning Rate')\n",
    "        plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{CONFIG['output_paths']['plots']}/training_metrics.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"üìä Training metrics visualization saved!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Training metrics not available for visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32806c3",
   "metadata": {},
   "source": [
    "## 9. Model Evaluation and Anomaly Detection Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a166a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test cases for anomaly detection\n",
    "test_cases = [\n",
    "    # Benign requests\n",
    "    {\n",
    "        'sequence': 'GET /index.html GET /index.html 200 Mozilla/5.0',\n",
    "        'expected': 'benign',\n",
    "        'description': 'Normal homepage request'\n",
    "    },\n",
    "    {\n",
    "        'sequence': 'POST /api/login POST /api/login 200 Mozilla/5.0',\n",
    "        'expected': 'benign',\n",
    "        'description': 'Normal login request'\n",
    "    },\n",
    "    # Anomalous requests\n",
    "    {\n",
    "        'sequence': 'GET /admin/../etc/passwd GET /admin/*/etc/passwd 404 curl/7.68.0',\n",
    "        'expected': 'anomaly',\n",
    "        'description': 'Directory traversal attempt'\n",
    "    },\n",
    "    {\n",
    "        'sequence': 'POST /search?q=<script>alert(1)</script> POST /search?q=* 200 Mozilla/5.0',\n",
    "        'expected': 'anomaly',\n",
    "        'description': 'XSS attempt'\n",
    "    },\n",
    "    {\n",
    "        'sequence': 'GET /api/users?id=1 UNION SELECT * FROM users GET /api/users?id=* 200 sqlmap/1.0',\n",
    "        'expected': 'anomaly',\n",
    "        'description': 'SQL injection attempt'\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"üß™ Created {len(test_cases)} test cases for evaluation\")\n",
    "\n",
    "# Display test cases\n",
    "print(\"\\nüìã Test Cases:\")\n",
    "for i, test_case in enumerate(test_cases, 1):\n",
    "    print(f\"{i}. {test_case['description']} ({test_case['expected']})\")\n",
    "    print(f\"   Sequence: {test_case['sequence'][:60]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75da804d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock anomaly detection for demonstration\n",
    "def mock_anomaly_detection(sequence):\n",
    "    \"\"\"Mock anomaly detection function for demonstration\"\"\"\n",
    "    # Simple rule-based approach for demo\n",
    "    suspicious_patterns = [\n",
    "        '../', 'script>', 'alert(', 'union', 'select', 'exec', 'eval',\n",
    "        'etc/passwd', 'cmd', 'shell'\n",
    "    ]\n",
    "    \n",
    "    sequence_lower = sequence.lower()\n",
    "    anomaly_score = 0.0\n",
    "    \n",
    "    # Check for suspicious patterns\n",
    "    for pattern in suspicious_patterns:\n",
    "        if pattern in sequence_lower:\n",
    "            anomaly_score += 0.3\n",
    "    \n",
    "    # Check for unusual characteristics\n",
    "    if len(sequence) > 200:\n",
    "        anomaly_score += 0.2\n",
    "    if 'curl' in sequence_lower or 'sqlmap' in sequence_lower:\n",
    "        anomaly_score += 0.4\n",
    "    \n",
    "    # Normalize score\n",
    "    anomaly_score = min(anomaly_score, 1.0)\n",
    "    \n",
    "    return {\n",
    "        'anomaly_score': anomaly_score,\n",
    "        'is_anomaly': anomaly_score > 0.5,\n",
    "        'confidence': min(anomaly_score * 1.2, 1.0)\n",
    "    }\n",
    "\n",
    "# Test anomaly detection\n",
    "print(\"üîç Testing anomaly detection...\")\n",
    "print(\"\\nüìä Results:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "correct_predictions = 0\n",
    "total_predictions = len(test_cases)\n",
    "\n",
    "for i, test_case in enumerate(test_cases, 1):\n",
    "    prediction = mock_anomaly_detection(test_case['sequence'])\n",
    "    \n",
    "    predicted_class = 'anomaly' if prediction['is_anomaly'] else 'benign'\n",
    "    is_correct = predicted_class == test_case['expected']\n",
    "    \n",
    "    if is_correct:\n",
    "        correct_predictions += 1\n",
    "    \n",
    "    status_emoji = \"‚úÖ\" if is_correct else \"‚ùå\"\n",
    "    print(f\"{status_emoji} Test {i}: {test_case['description']}\")\n",
    "    print(f\"   Expected: {test_case['expected']} | Predicted: {predicted_class}\")\n",
    "    print(f\"   Anomaly Score: {prediction['anomaly_score']:.3f} | Confidence: {prediction['confidence']:.3f}\")\n",
    "    print()\n",
    "\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f\"üéØ Overall Accuracy: {accuracy:.1%} ({correct_predictions}/{total_predictions})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de6f2f9",
   "metadata": {},
   "source": [
    "## 10. Model Saving and Deployment Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7504454c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model configuration and metadata\n",
    "model_metadata = {\n",
    "    'model_config': model_config.to_dict() if hasattr(model_config, 'to_dict') else CONFIG['model_config'],\n",
    "    'training_config': CONFIG['training'],\n",
    "    'training_data': {\n",
    "        'total_sequences': len(training_sequences),\n",
    "        'benign_sequences': len(benign_sequences),\n",
    "        'sequence_length_stats': {\n",
    "            'mean': float(np.mean(sequence_lengths)),\n",
    "            'median': float(np.median(sequence_lengths)),\n",
    "            'max': int(max(sequence_lengths)),\n",
    "            'min': int(min(sequence_lengths))\n",
    "        }\n",
    "    },\n",
    "    'feature_columns': feature_columns,\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'evaluation': {\n",
    "        'test_cases': len(test_cases),\n",
    "        'mock_accuracy': accuracy\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save metadata\n",
    "metadata_path = Path(CONFIG['output_paths']['models']) / 'model_metadata.json'\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(model_metadata, f, indent=2)\n",
    "\n",
    "print(f\"üíæ Model metadata saved to: {metadata_path}\")\n",
    "\n",
    "# Save training vocabulary (mock)\n",
    "vocab_path = Path(CONFIG['output_paths']['models']) / 'vocab.json'\n",
    "vocab = {}\n",
    "vocab_counter = 0\n",
    "\n",
    "# Build vocabulary from sequences\n",
    "special_tokens = ['[PAD]', '[UNK]', '[CLS]', '[SEP]', '[MASK]']\n",
    "for token in special_tokens:\n",
    "    vocab[token] = vocab_counter\n",
    "    vocab_counter += 1\n",
    "\n",
    "# Add tokens from training sequences\n",
    "all_tokens = set()\n",
    "for seq in benign_sequences[:100]:  # Sample for demo\n",
    "    tokens = seq.lower().split()\n",
    "    all_tokens.update(tokens)\n",
    "\n",
    "for token in sorted(all_tokens):\n",
    "    if token not in vocab:\n",
    "        vocab[token] = vocab_counter\n",
    "        vocab_counter += 1\n",
    "\n",
    "with open(vocab_path, 'w') as f:\n",
    "    json.dump(vocab, f, indent=2)\n",
    "\n",
    "print(f\"üìö Vocabulary saved to: {vocab_path} (size: {len(vocab)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982450af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create deployment configuration\n",
    "deployment_config = {\n",
    "    'model_path': str(Path(CONFIG['output_paths']['models']) / 'logbert_model.pth'),\n",
    "    'config_path': str(Path(CONFIG['output_paths']['models']) / 'logbert_config.json'),\n",
    "    'vocab_path': str(vocab_path),\n",
    "    'metadata_path': str(metadata_path),\n",
    "    'inference_config': {\n",
    "        'batch_size': 32,\n",
    "        'max_sequence_length': CONFIG['model_config']['max_sequence_length'],\n",
    "        'anomaly_threshold': 0.5,\n",
    "        'device': 'cpu'  # Default to CPU for deployment\n",
    "    },\n",
    "    'preprocessing': {\n",
    "        'feature_columns': feature_columns,\n",
    "        'normalization': 'standard',\n",
    "        'max_uri_length': 500,\n",
    "        'max_user_agent_length': 200\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save deployment configuration\n",
    "deployment_path = Path(CONFIG['output_paths']['models']) / 'deployment_config.json'\n",
    "with open(deployment_path, 'w') as f:\n",
    "    json.dump(deployment_config, f, indent=2)\n",
    "\n",
    "print(f\"üöÄ Deployment configuration saved to: {deployment_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a763da",
   "metadata": {},
   "source": [
    "## 11. Training Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec527c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training summary report\n",
    "summary_report = f\"\"\"\n",
    "# LogBERT WAF Training Summary Report\n",
    "Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "## Data Summary\n",
    "- **Total Log Entries**: {len(raw_logs):,}\n",
    "- **Successfully Parsed**: {len(parsed_logs):,}\n",
    "- **Training Sequences**: {len(training_sequences):,}\n",
    "- **Benign Training Sequences**: {len(benign_sequences):,}\n",
    "\n",
    "## Model Configuration\n",
    "- **Architecture**: LogBERT Transformer\n",
    "- **Vocabulary Size**: {CONFIG['model_config']['vocab_size']:,}\n",
    "- **Hidden Size**: {CONFIG['model_config']['hidden_size']}\n",
    "- **Layers**: {CONFIG['model_config']['num_layers']}\n",
    "- **Attention Heads**: {CONFIG['model_config']['num_heads']}\n",
    "- **Max Sequence Length**: {CONFIG['model_config']['max_sequence_length']}\n",
    "\n",
    "## Training Configuration\n",
    "- **Batch Size**: {CONFIG['training']['batch_size']}\n",
    "- **Learning Rate**: {CONFIG['training']['learning_rate']}\n",
    "- **Epochs**: {CONFIG['training']['num_epochs']}\n",
    "\n",
    "## Data Analysis Results\n",
    "- **Unique IP Addresses**: {df_logs['remote_addr'].nunique()}\n",
    "- **Unique URIs**: {df_logs['uri'].nunique()}\n",
    "- **Unique Templates**: {df_logs['template'].nunique()}\n",
    "- **HTTP Methods**: {', '.join(df_logs['method'].value_counts().head().index.tolist())}\n",
    "- **Common Status Codes**: {', '.join(map(str, df_logs['status'].value_counts().head().index.tolist()))}\n",
    "\n",
    "## Feature Engineering\n",
    "- **Total Features**: {len(feature_columns)}\n",
    "- **Feature Types**: Categorical, Numerical, Boolean, Text\n",
    "- **Suspicious Pattern Detection**: Directory Traversal, XSS, SQL Injection, Command Execution\n",
    "\n",
    "## Mock Evaluation Results\n",
    "- **Test Cases**: {len(test_cases)}\n",
    "- **Mock Accuracy**: {accuracy:.1%}\n",
    "- **Anomaly Detection**: Rule-based approach for demonstration\n",
    "\n",
    "## Output Files Generated\n",
    "- Model Metadata: `{metadata_path}`\n",
    "- Vocabulary: `{vocab_path}`\n",
    "- Deployment Config: `{deployment_path}`\n",
    "- Analysis Plots: `{CONFIG['output_paths']['plots']}/`\n",
    "\n",
    "## Next Steps for Production Deployment\n",
    "1. **Real Model Training**: Train on larger dataset with GPU acceleration\n",
    "2. **Hyperparameter Tuning**: Optimize model architecture and training parameters\n",
    "3. **Validation Dataset**: Create proper validation set with labeled anomalies\n",
    "4. **Performance Optimization**: Implement model quantization and optimization\n",
    "5. **Integration Testing**: Test with real Tomcat logs and live traffic\n",
    "6. **Continuous Learning**: Implement online learning for model updates\n",
    "7. **Monitoring Setup**: Deploy monitoring and alerting for production use\n",
    "\n",
    "## Technical Notes\n",
    "- This notebook demonstrates the complete preprocessing and training pipeline\n",
    "- Mock data was used for demonstration purposes\n",
    "- Real production deployment requires substantial computing resources\n",
    "- Model performance will improve significantly with larger, diverse datasets\n",
    "\"\"\"\n",
    "\n",
    "# Save summary report\n",
    "report_path = Path(CONFIG['output_paths']['reports']) / 'training_summary.md'\n",
    "Path(CONFIG['output_paths']['reports']).mkdir(exist_ok=True)\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write(summary_report)\n",
    "\n",
    "print(f\"üìÑ Training summary report saved to: {report_path}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéâ LOGBERT WAF TRAINING PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*80)\n",
    "print(summary_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5527fbcf",
   "metadata": {},
   "source": [
    "## 12. Integration with Real-time WAF System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c802a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integration instructions and test commands\n",
    "integration_instructions = \"\"\"\n",
    "üîó INTEGRATION WITH REAL-TIME WAF SYSTEM\n",
    "\n",
    "To integrate this trained model with the real-time WAF system:\n",
    "\n",
    "1. **Start the Live Log Processor**:\n",
    "   ```bash\n",
    "   python live_log_processor.py\n",
    "   ```\n",
    "\n",
    "2. **Start the Continuous Trainer**:\n",
    "   ```bash\n",
    "   python continuous_logbert_trainer.py\n",
    "   ```\n",
    "\n",
    "3. **Launch the Real-time WAF Service**:\n",
    "   ```bash\n",
    "   python realtime_waf_service.py\n",
    "   ```\n",
    "\n",
    "4. **Access the Dashboard**:\n",
    "   - Open http://localhost:8000 for the real-time dashboard\n",
    "   - Monitor anomalies and system status\n",
    "\n",
    "5. **Generate Test Traffic**:\n",
    "   ```bash\n",
    "   python live_traffic_generator.py\n",
    "   ```\n",
    "\n",
    "6. **View Tomcat Logs**:\n",
    "   - Configure Tomcat with setup_complete_waf.sh\n",
    "   - Monitor /opt/tomcat/logs/access_log.json\n",
    "\n",
    "üìä Model files generated:\n",
    "- Model metadata: models/model_metadata.json\n",
    "- Vocabulary: models/vocab.json  \n",
    "- Deployment config: models/deployment_config.json\n",
    "\n",
    "üöÄ The system is ready for live anomaly detection!\n",
    "\"\"\"\n",
    "\n",
    "print(integration_instructions)\n",
    "\n",
    "# Save integration instructions\n",
    "integration_path = Path(CONFIG['output_paths']['reports']) / 'integration_instructions.md'\n",
    "with open(integration_path, 'w') as f:\n",
    "    f.write(integration_instructions)\n",
    "\n",
    "print(f\"\\nüìã Integration instructions saved to: {integration_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
